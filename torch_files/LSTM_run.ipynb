{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30da53db-f4aa-4efe-9979-917de8439494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import LSTM_encoder as s2s\n",
    "import torch_functions as fn\n",
    "import LSTM_plotting as s2s_plt\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec216e26-57e4-4c45-989d-34f33ee70527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and prepare data\n",
    "ocr = pd.read_csv('./pit_data/SP1.txt', index_col='timestamp_utc')\n",
    "stamps = ocr.index.values.astype(float)\n",
    "datetimes = np.zeros(len(stamps)).astype(datetime)\n",
    "\n",
    "for ii in range(len(datetimes)):\n",
    "    datetimes[ii] = fn.OrdinalToDatetime(stamps[ii])\n",
    "\n",
    "ocr.set_index(datetimes, inplace=True)\n",
    "pp_cols = [v for v in ocr.columns if \"porePressure_\" in v]  # allows any pp depths, as the depth varies from pit to pit\n",
    "VWC_cols = [v for v in ocr.columns if \"VWC_\" in v]  # allows any water content depths, as the depth varies from pit to pit\n",
    "ocr[pp_cols] = ocr[pp_cols].mask(ocr[pp_cols] < -14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6cda43-c000-4ab6-a6f7-71fbf911ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in forecasted rainfall\n",
    "# this will take a while\n",
    "for i in range(2,38,2):\n",
    "    ocr = fn.add_max_rainfall(ocr, i, 0, noise=False)\n",
    "\n",
    "# rearrange cols\n",
    "ocr = ocr.loc[:,[ocr.columns[0],'2hr_total_rfall', '2hr_max_rfall', '4hr_total_rfall', '4hr_max_rfall',\n",
    "       '6hr_total_rfall', '6hr_max_rfall', '8hr_total_rfall', '8hr_max_rfall',\n",
    "       '10hr_total_rfall', '10hr_max_rfall', '12hr_total_rfall',\n",
    "       '12hr_max_rfall', '14hr_total_rfall', '14hr_max_rfall',\n",
    "       '16hr_total_rfall', '16hr_max_rfall', '18hr_total_rfall',\n",
    "       '18hr_max_rfall', '20hr_total_rfall', '20hr_max_rfall',\n",
    "       '22hr_total_rfall', '22hr_max_rfall', '24hr_total_rfall',\n",
    "       '24hr_max_rfall', '26hr_total_rfall', '26hr_max_rfall',\n",
    "       '28hr_total_rfall', '28hr_max_rfall', '30hr_total_rfall',\n",
    "       '30hr_max_rfall', '32hr_total_rfall', '32hr_max_rfall',\n",
    "       '34hr_total_rfall', '34hr_max_rfall', '36hr_total_rfall',\n",
    "       '36hr_max_rfall', VWC_cols[0], VWC_cols[1], VWC_cols[2],\n",
    "       pp_cols[0], pp_cols[1], pp_cols[2]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c012b21d-ed45-47a1-867d-a53630d2c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target data size:  (26305, 3)\n",
      "Features size:  (36, 43)\n",
      "Targets size:  (36, 3)\n",
      "features size:  (730, 36, 43)\n",
      "Targets size:  (730, 36, 3)\n",
      "Preparations complete!\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "data = ocr\n",
    "data_scaling = preprocessing.MinMaxScaler(feature_range=(0,1)).fit(data.iloc[:,:])\n",
    "data_scaled = pd.DataFrame(data_scaling.transform(data.iloc[:,:]),index=ocr.index)\n",
    "data_scaled_df = data_scaled.fillna(-1)\n",
    "\n",
    "# finally, prepare features and targets\n",
    "features, targets, target_indices = fn.lstm_prep(data_scaled_df.index.values, data_scaled_df.values, 3, 36, 36)\n",
    "\n",
    "# we choose 3 here for # of targets, because we're wanting to predict pore pressure, which is the last 3 columns\n",
    "# 36 is the width of our \"moving window\". 36 time entries. This is supposed to represent 36 hours.\n",
    "\n",
    "# create bounds for the prediction intervals\n",
    "intervals = np.zeros(len(target_indices))\n",
    "for i in range(0,len(intervals),targets.shape[1]):\n",
    "    intervals[i]=1\n",
    "\n",
    "intervals[intervals==0] = np.nan\n",
    "\n",
    "binary_indices = np.copy(target_indices)\n",
    "\n",
    "for i in range(0,len(binary_indices),36):\n",
    "    binary_indices[i]=np.datetime64(\"NaT\")\n",
    "    \n",
    "# set -1s to nan to be ignored\n",
    "targets[targets==-1]=np.nan\n",
    "\n",
    "# split training/testing data based on water years 1&2\n",
    "split = 0.7\n",
    "train_features = features[:int((len(features)*split))]  # use 70% as training\n",
    "test_features = features[int((len(features)*split)):]  # use 30% as validation\n",
    "\n",
    "train_targets = targets[:int((len(features)*split))]  # use 70% as training\n",
    "test_targets = targets[int((len(features)*split)):]  # use 30% as validation\n",
    "test_indices = target_indices[-test_targets.shape[0]*test_targets.shape[1]:]\n",
    "\n",
    "# convert windowed data from np.array to PyTorch tensor\n",
    "X_train, Y_train, X_test, Y_test = proc.numpy_to_torch(train_features, train_targets, test_features, test_targets)\n",
    "\n",
    "print(\"Preparations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74d33a19-8dbb-4c1c-9df6-fa17bc2bbe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26305, 43)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efda73db-8633-4818-8890-34dd86354b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 36, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3787d0-c10e-41eb-923c-19b78de450d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([510, 36, 43])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "688d2c6e-d2fe-453b-b48b-4931d50182c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([510, 36, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e2bedd6-a00d-4b64-a4f9-aab5820dfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50/50 [00:10<00:00,  4.78it/s, loss=nan]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 3, got 43",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plot predictions on train/test data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43ms2s_plt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_train_test_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox (University of Oregon)/GitHub/LSTM-Multistep-Prediction/LSTM_plotting.py:33\u001b[0m, in \u001b[0;36mplot_train_test_results\u001b[0;34m(lstm_model, Xtrain, Ytrain, Xtest, Ytest, num_rows)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rows):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# train set\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     X_train_plt \u001b[38;5;241m=\u001b[39m Xtrain[:, ii, :]\n\u001b[0;32m---> 33\u001b[0m     Y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_plt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     ax[ii, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, iw), Xtrain[:, ii, \u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m     ax[ii, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(iw \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, iw \u001b[38;5;241m+\u001b[39m ow), np\u001b[38;5;241m.\u001b[39mconcatenate([[Xtrain[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ii, \u001b[38;5;241m0\u001b[39m]], Ytrain[:, ii, \u001b[38;5;241m0\u001b[39m]]),\n\u001b[1;32m     37\u001b[0m                  color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.42\u001b[39m, \u001b[38;5;241m0.72\u001b[39m), linewidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox (University of Oregon)/GitHub/LSTM-Multistep-Prediction/LSTM_encoder.py:302\u001b[0m, in \u001b[0;36mlstm_seq2seq.predict\u001b[0;34m(self, input_tensor, target_tensor)\u001b[0m\n\u001b[1;32m    299\u001b[0m decoder_hidden \u001b[38;5;241m=\u001b[39m encoder_hidden\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(target_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 302\u001b[0m     decoder_output, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     outputs[t] \u001b[38;5;241m=\u001b[39m decoder_output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    304\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m decoder_output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TFML/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dropbox (University of Oregon)/GitHub/LSTM-Multistep-Prediction/LSTM_encoder.py:137\u001b[0m, in \u001b[0;36mlstm_decoder.forward\u001b[0;34m(self, x_input, encoder_hidden_states)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_input, encoder_hidden_states):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m'''        \u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    : param x_input:                    should be 2D (batch_size, input_size)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    : param encoder_hidden_states:      hidden states\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     lstm_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))     \n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TFML/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TFML/lib/python3.9/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TFML/lib/python3.9/site-packages/torch/nn/modules/rnn.py:684\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    680\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    683\u001b[0m                        ):\n\u001b[0;32m--> 684\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    686\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    688\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TFML/lib/python3.9/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 3, got 43"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify model parameters and train\n",
    "model = s2s.lstm_seq2seq(input_size = X_train.shape[2], target_size=3, hidden_size = 3)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = 50, target_len = Y_train.shape[0], batch_size = 36, training_prediction = 'mixed_teacher_forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n",
    "print(loss)\n",
    "# plot predictions on train/test data\n",
    "s2s_plt.plot_train_test_results(model, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b9443-1920-4b11-9fc1-17cfbeb30d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model parameters and train\n",
    "model = lstm_encoder_decoder.lstm_seq2seq(input_size = X_train.shape[2], hidden_size = 15)\n",
    "loss = model.train_model(X_train, Y_train, n_epochs = 50, target_len = ow, batch_size = 5, training_prediction = 'mixed_teacher_forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n",
    "\n",
    "# plot predictions on train/test data\n",
    "plotting.plot_train_test_results(model, Xtrain, Ytrain, Xtest, Ytest)\n",
    "\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
